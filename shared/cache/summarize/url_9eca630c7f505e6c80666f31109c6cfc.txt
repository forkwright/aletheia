 [2401.02843] Thousands of AI Authors on the Future of AI <meta property="og:description" content="In the largest survey of its kind, 2,778 researchers who had published in top-tier artificial intelligence (AI) venues gave predictions on the pace of AI progress and the nature and impacts of advanced AI systems The aggregate forecasts give at least a 50% chance of AI systems achieving several milestones by 2028, including autonomously constructing a payment processing site from scratch, creating a song indistinguishable from a new song by a popular musician, and autonomously downloading and fine-tuning a large language model. If science continues undisrupted, the chance of unaided machines outperforming humans in every possible task was estimated at 10% by 2027, and 50% by 2047. The latter estimate is 13 years earlier than that reached in a similar survey we conducted only one year earlier [Grace et al., 2022]. However, the chance of all human occupations becoming fully automatable was forecast to reach 10% by 2037, and 50% as late as 2116 (compared to 2164 in the 2022 survey). Most respondents expressed substantial uncertainty about the long-term value of AI progress: While 68.3% thought good outcomes from superhuman AI are more likely than bad, of these net optimists 48% gave at least a 5% chance of extremely bad outcomes such as human extinction, and 59% of net pessimists gave 5% or more to extremely good outcomes. Between 38% and 51% of respondents gave at least a 10% chance to advanced AI leading to outcomes as bad as human extinction. More than half suggested that &#34;substantial&#34; or &#34;extreme&#34; concern is warranted about six different AI-related scenarios, including misinformation, authoritarian control, and inequality. There was disagreement about whether faster or slower AI progress would be better for the future of humanity. However, there was broad agreement that research aimed at minimizing potential risks from AI systems ought to be prioritized more."/> Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate cs arXiv:2401.02843 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search <source media="(min-width: 501px)" srcset="/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg 400w" sizes="400w" /> open search GO open navigation menu quick links Login Help Pages About <!-- rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/"> <rdf:Description rdf:about="/abs/2401.02843" dc:identifier="/abs/2401.02843" dc:title="Thousands of AI Authors on the Future of AI" trackback:ping="/trackback/2401.02843" /> --> Computer Science > Computers and Society arXiv:2401.02843 (cs) [Submitted on 5 Jan 2024 (v1), last revised 8 Oct 2025 (this version, v3)] Title:Thousands of AI Authors on the Future of AI Authors:Katja Grace, Harlan Stewart, Julia Fabienne Sandkühler, Stephen Thomas, Ben Weinstein-Raun, Jan Brauner, Richard C. Korzekwa View a PDF of the paper titled Thousands of AI Authors on the Future of AI, by Katja Grace and 6 other authors View PDF HTML (experimental) Abstract:In the largest survey of its kind, 2,778 researchers who had published in top-tier artificial intelligence (AI) venues gave predictions on the pace of AI progress and the nature and impacts of advanced AI systems The aggregate forecasts give at least a 50% chance of AI systems achieving several milestones by 2028, including autonomously constructing a payment processing site from scratch, creating a song indistinguishable from a new song by a popular musician, and autonomously downloading and fine-tuning a large language model. If science continues undisrupted, the chance of unaided machines outperforming humans in every possible task was estimated at 10% by 2027, and 50% by 2047. The latter estimate is 13 years earlier than that reached in a similar survey we conducted only one year earlier [Grace et al., 2022]. However, the chance of all human occupations becoming fully automatable was forecast to reach 10% by 2037, and 50% as late as 2116 (compared to 2164 in the 2022 survey). Most respondents expressed substantial uncertainty about the long-term value of AI progress: While 68.3% thought good outcomes from superhuman AI are more likely than bad, of these net optimists 48% gave at least a 5% chance of extremely bad outcomes such as human extinction, and 59% of net pessimists gave 5% or more to extremely good outcomes. Between 38% and 51% of respondents gave at least a 10% chance to advanced AI leading to outcomes as bad as human extinction. More than half suggested that &#34;substantial&#34; or &#34;extreme&#34; concern is warranted about six different AI-related scenarios, including misinformation, authoritarian control, and inequality. There was disagreement about whether faster or slower AI progress would be better for the future of humanity. However, there was broad agreement that research aimed at minimizing potential risks from AI systems ought to be prioritized more. Comments: The asterisk indicates the corresponding author. The dagger indicates equal contribution Subjects: Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) Cite as: arXiv:2401.02843 [cs.CY] (or arXiv:2401.02843v3 [cs.CY] for this version) https://doi.org/10.48550/arXiv.2401.02843 Focus to learn more arXiv-issued DOI via DataCite Journalreference: Journal of Artificial Intelligence Research 84:9 (2025) Related DOI: https://doi.org/10.1613/jair.1.19087 Focus to learn more DOI(s) linking to related resources Submission history From: Julia Fabienne Sandkühler [view email] [v1] Fri, 5 Jan 2024 14:53:09 UTC (4,906 KB) [v2] Tue, 30 Apr 2024 18:15:42 UTC (4,907 KB) [v3] Wed, 8 Oct 2025 18:38:53 UTC (4,906 KB) Full-text links: Access Paper: View a PDF of the paper titled Thousands of AI Authors on the Future of AI, by Katja Grace and 6 other authorsView PDFHTML (experimental)TeX Source view license Current browse context: cs.CY <a class="abs-button prev-url" href="/prevnext?id=2401.02843function=prevcontext=cs.CY" accesskey="p" title="previous in cs.CY (accesskey p)" rel="nofollow">prev | <a class="abs-button next-url" href="/prevnext?id=2401.02843function=nextcontext=cs.CY" accesskey="n" title="next in cs.CY (accesskey n)" rel="nofollow">next new | recent | 2024-01 Change to browse by: cs cs.AI cs.LG References Citations NASA ADSGoogle Scholar Semantic Scholar export BibTeX citation Loading... BibTeX formatted citation loading... Data provided by: Bookmark<a class="abs-button abs-button-grey abs-button-small" href="http://www.bibsonomy.org/BibtexHandler?requTask=uploadurl=https://arxiv.org/abs/2401.02843description=Thousands of AI Authors on the Future of AI" title="Bookmark on BibSonomy"> <img src="/static/browse/0.3.4/images/icons/social/bibsonomy.png" alt="BibSonomy logo"/> <a class="abs-button abs-button-grey abs-button-small" href="https://reddit.com/submit?url=https://arxiv.org/abs/2401.02843title=Thousands of AI Authors on the Future of AI" title="Bookmark on Reddit"> <img src="/static/browse/0.3.4/images/icons/social/reddit.png" alt="Reddit logo"/> Bibliographic Tools Bibliographic and Citation Tools <input id="bibex-toggle" type="checkbox" class="lab-toggle" data-script-url="/static/browse/0.3.4/bibex/bibex.js?20241202"> Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) <input id="connectedpapers-toggle" type="checkbox" class="lab-toggle" data-script-url="/static/browse/0.3.4/js/connectedpapers.js" aria-labelledby="label-for-connected-papers"> Connected Papers Toggle Connected Papers (What is Connected Papers?) <input id="litmaps-toggle" type="checkbox" class="lab-toggle" data-script-url="/static/browse/0.3.4/js/litmaps.js?20210617" aria-labelledby="label-for-litmaps"> Litmaps Toggle Litmaps (What is Litmaps?) <input id="scite-toggle" type="checkbox" class="lab-toggle" data-script-url="/static/browse/0.3.4/js/scite.js?20210617" aria-labelledby="label-for-scite"> scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article <input id="alphaxiv-toggle" data-script-url="/static/browse/0.3.4/js/alphaxiv.js" type="checkbox" class="lab-toggle" aria-labelledby="label-for-alphaxiv"> alphaXiv Toggle alphaXiv (What is alphaXiv?) <input id="catalyzex-toggle" data-script-url="/static/browse/0.3.4/js/catalyzex.js" type="checkbox" class="lab-toggle" aria-labelledby="label-for-cx"> Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) <input id="dagshub-toggle" data-script-url="/static/browse/0.3.4/js/dagshub.js" type="checkbox" class="lab-toggle" aria-labelledby="label-for-dagshub"> DagsHub Toggle DagsHub (What is DagsHub?) <input id="gotitpub-toggle" data-script-url="/static/browse/0.3.4/js/gotitpub.js" type="checkbox" class="lab-toggle" aria-labelledby="label-for-gotitpub"> GotitPub Toggle Gotit.pub (What is GotitPub?) <input id="huggingface-toggle" data-script-url="/static/browse/0.3.4/js/huggingface.js" type="checkbox" class="lab-toggle" aria-labelledby="label-for-huggingface"> Huggingface Toggle Hugging Face (What is Huggingface?) <input id="paperwithcode-toggle" data-script-url="/static/browse/0.3.4/js/paperswithcode.js" type="checkbox" class="lab-toggle" aria-labelledby="label-for-pwc"> Links to Code Toggle Papers with Code (What is Papers with Code?) <input id="sciencecast-toggle" data-script-url="/static/browse/0.3.4/js/sciencecast.js" type="checkbox" class="lab-toggle" aria-labelledby="label-for-sciencecast"> ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos <input id="replicate-toggle" data-script-url="/static/browse/0.3.4/js/replicate.js" type="checkbox" class="lab-toggle" aria-labelledby="label-for-replicate"> Replicate Toggle Replicate (What is Replicate?) <input id="spaces-toggle" data-script-url="/static/browse/0.3.4/js/spaces.js" type="checkbox" class="lab-toggle" aria-labelledby="label-for-spaces"> Spaces Toggle Hugging Face Spaces (What is Spaces?) <input id="txyz-toggle" data-script-url="/static/browse/0.3.4/js/txyz.js" type="checkbox" class="lab-toggle" aria-labelledby="label-for-txyz"> Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers Recommenders and Search Tools <input id="influenceflower-toggle" data-script-url="/static/browse/0.3.4/js/influenceflower.js" type="checkbox" class="lab-toggle" aria-labelledby="label-for-influenceflower"> Link to Influence Flower Influence Flower (What are Influence Flowers?) Core recommender toggle CORE Recommender (What is CORE?) Author Venue Institution Topic About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?) mathjaxToggle(); About Help contact arXivClick here to contact arXiv Contact subscribe to arXiv mailingsClick here to subscribe Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status 